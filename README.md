[Literature Review Table](http://tiny.cc/literature-review)
| No | Title                                                                                                                                                                                                                                                       | Authors                                                                                                              | Journal/Conferece                                                                                                         | Year       | Race/Gender                | Code (Github or Journal supplemental)                                           | Image/Video  | Data Source                                                                                                                                                                                                  | # Obs                                                                                                                                                                                                                          | Accuracy                                                                                                                           |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |           |   |                                                                |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
|----|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------|------------|----------------------------|---------------------------------------------------------------------------------|--------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------|---|----------------------------------------------------------------|-----|-----|---|---|---|---|---|---|---|---|---|---|---|---|---|
| 1  | [A hybrid approach to gender classification from face images](https://ieeexplore.ieee.org/abstract/document/4761883)                                                                                                                                        | Ziyi Xu; Li Lu; Pengfei Shi                                                                                          | 19th International Conference on Pattern Recognition                                                                      | 2008       | Gender                     |                                                                                 | Image        | [FERET](https://www.nist.gov/itl/products-and-services/color-feret-database) [AR Face Database](https://www2.ece.ohio-state.edu/~aleix/ARdatabase.html)                                                      | 14756 - subset of 12K, 1K for validation                                                                                                                                                                                       | 82.97                                                                                                                              |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |           |   |                                                                |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
| 2  | [Mitigating Gender Bias in Face Recognition Using the von Mises-Fisher Mixture Model](https://proceedings.mlr.press/v162/conti22a.html)                                                                                                                     | Jean-Rémy Conti, Nathan Noiry, Stephan Clemencon, Vincent Despiegel, Stéphane Gentric                                | 39th International Conference on Machine Learning                                                                         | 2022       | Gender                     |                                                                                 | Image        |  [MS1MV3, MS-Celeb-1M-v1c-r](https://github.com/JDAI-CV/FaceX-Zoo/blob/main/training_mode/README.md)                                                                                                         | 3.28M images of 73k identities for the pretraining of AdaCos, CosFace and CurricularFace with a MobileFaceNet backbone and 5.1M images with 93k identities for the training of ArcFace, also used to train  the Ethical Module |                                                                                                                                    |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |           |   |                                                                |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
| 3  | [Diagnosing Gender Bias in Image Recognition Systems](https://journals.sagepub.com/doi/full/10.1177/2378023120967171#bibr68-2378023120967171)                                                                                                               | Carsten Schwemme, Carly Knight, Emily D. Bello-Pardo, Stan Oklobdzija, Martijn Schoonvelde, and Jeffrey W. Lockhart  | American Sociological Association - Socius: Sociological Research for a Dynamic World                                     | 2020       | Gender                     | https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/2CEYWV | Image        | [Replication Data for: Diagnosing Gender Bias in Image Recognition Systems](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/2CEYWV)                                                 | two data sets containing images associated with members of the 115th U.S. Congress: a data set of official headshots and a set of images tweeted by these members (9250 images)                                                | 62.4 for found dataset to detect if women/men are recognized by GCV                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |           |   |                                                                |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
| 4  | [Learning local binary patterns for gender classification on real-world face images](https://www.sciencedirect.com/science/article/pii/S0167865511001607)                                                                                                   | Caifeng Shan                                                                                                         | Pattern Recognition Letters                                                                                               | 2011       | Gender                     |                                                                                 | Image        | [LFW database](http://vis-www.cs.umass.edu/lfw/)                                                                                                                                                             | 7443 images                                                                                                                                                                                                                    | 91.27 - 94.81                                                                                                                      |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |           |   |                                                                |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
| 5  | [Fairness for Image Generation with Uncertain Sensitive Attributes](https://proceedings.mlr.press/v139/jalal21b.html)                                                                                                                                       | Ajil Jalal, Sushrut Karmalkar, Jessica Hoffmann, Alex Dimakis, Eric Price                                            | 38th International Conference on Machine Learning                                                                         | 2021       | Race (any protected group) | https://github.com/ajiljalal/ code-cs-fairness                                  | Image        |  [MNIST(LeCun, 1998),FlickrFaces-HQ (Karrasetal.,2019) and AFHQ cat & dog (Choietal.,2020b) datasets]                                                                                                        |                                                                                                                                                                                                                                | 90.8 (adult and kids with glasses),82.4  (numbers)                                                                                 |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |           |   |                                                                |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
| 6  | [Characterizing Bias in Classifiers using Generative Models](https://proceedings.neurips.cc/paper_files/paper/2019/file/7f018eb7b301a66658931cb8a93fd6e8-Paper.pdf)                                                                                         | Daniel McDuff,Yale Song and Ashish Kapoor, ShuangMa                                                                  | NeurIPS                                                                                                                   | 2019       | Race, Gender               | https://github.com/danmcduff/characterizingBias                                 | Image        | [MS-CELEB-1M]( https://github.com/JDAI-CV/FaceX-Zoo/blob/main/training_mode/README.md)                                                                                                                       | 20k images                                                                                                                                                                                                                     | 97.16 (100 - error rate for detecting gender in all race sub groups)                                                               |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |           |   |                                                                |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
| 7  | [Machine Learning Applied to Perception: Decision Images for Gender Classification](https://papers.nips.cc/paper_files/paper/2004/hash/1b113258af3968aaf3969ca67e744ff8-Abstract.html)                                                                      | Felix A. Wichmann, Arnulf Graf, Heinrich Bülthoff, Eero Simoncelli, Bernhard Schölkopf                               | NeurIPS                                                                                                                   | 2004       | Gender                     |                                                                                 | Image        | http://faces.kyb.tuebingen.mpg.de                                                                                                                                                                            | 200 images                                                                                                                                                                                                                     |                                                                                                                                    |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |           |   |                                                                |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
| 8  | [Anatomizing Bias in Facial Analysis](https://ojs.aaai.org/index.php/AAAI/article/view/21500)                                                                                                                                                               | Richa Singh,Puspita Majumdar, Surbhi Mittal, Mayank Vatsa                                                            | AAAI Conference on Artificial Intelligence                                                                                | 2022       | Gender, Race               |                                                                                 | Image        | ref - table 1                                                                                                                                                                                                |                                                                                                                                                                                                                                |                                                                                                                                    |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |           |   |                                                                |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
| 9  | [Describing people: A poselet-based approach to attribute classification](https://ieeexplore.ieee.org/abstract/document/6126413)                                                                                                                            | Lubomir Bourdev; Subhransu Maji; Jitendra Malik                                                                      | ICCV                                                                                                                      | 2011       |                            |                                                                                 | Image        | [H3D dataset](https://usa.honda-ri.com/h3d) [Pascal Voc 2010 dataset](http://www. pascalnetwork. org/challenges/VOC/voc2010/workshop/index.html)                                                             | 8035  images                                                                                                                                                                                                                   |                                                                                                                                    |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |           |   |                                                                |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
| 10 | [Balanced Datasets Are Not Enough: Estimating and Mitigating Gender Bias in Deep Image Representations](https://openaccess.thecvf.com/content_ICCV_2019/papers/Wang_Balanced_Datasets_Are_Not_Enough_Estimating_and_Mitigating_Gender_Bias_ICCV_2019_paper) | Tianlu Wang, Jieyu Zhao, Mark Yatskar, Kai-Wei Chang, Vicente Ordonez                                                | ICCV                                                                                                                      | 2019       | Gender                     |                                                                                 | Image        | [COCO](https://cocodataset.org/#home) and [imSitu](http://imsitu.org/)                                                                                                                                       | 22826,5367,5473 and 24301,7730,7669 images in the training, validation and testing set for COCO and imSitu respectively                                                                                                        |                                                                                                                                    |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |           |   |                                                                |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
| 11 | [Women Also Snowboard: Overcoming Bias in Captioning Models](https://openaccess.thecvf.com/content_ECCV_2018/papers/Lisa_Anne_Hendricks_Women_also_Snowboard_ECCV_2018_paper)                                                                               | Lisa Anne Hendricks, Kaylee Burns, Kate Saenko, Trevor Darrell & Anna Rohrbach                                       | ECCV                                                                                                                      | 2018       | Gender                     |                                                                                 | Image        | [COCO](https://cocodataset.org/#home)                                                                                                                                                                        | 1000 images for training                                                                                                                                                                                                       | 92.98                                                                                                                              |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |           |   |                                                                |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
| 12 | [Understanding and Evaluating Racial Biases in Image Captioning](https://openaccess.thecvf.com/content/ICCV2021/papers/Zhao_Understanding_and_Evaluating_Racial_Biases_in_Image_Captioning_ICCV_2021_paper)                                                 | Dora Zhao   Angelina Wang   Olga Russakovsky                                                                         | ICCV                                                                                                                      | 2021       | Gender, Race               | https://princetonvisualai.github.io/imagecaptioning-bias/                       | Image        | [COCO](https://cocodataset.org/#home)                                                                                                                                                                        | 15762 images and 28315 person instances, 10780 labelled images, 876 images used for evaluation                                                                                                                                 | 68 - AUC                                                                                                                           |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |           |   |                                                                |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
| 13 | [Quantifying Societal Bias Amplification in Image Captioning](https://ieeexplore.ieee.org/document/9880317)                                                                                                                                                 | Yusuke Hirota; Yuta Nakashima; Noa Garcia                                                                            | IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)                                                     | 2022       | Gender, Race               |                                                                                 | Image        | [MSCOCO captions dataset](https://cocodataset.org/#home)                                                                                                                                                     | 5,966 for training and 662 for test in gender, and 1, 972 for training and 220 for test in race                                                                                                                                |                                                                                                                                    |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |           |   |                                                                |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
| 14 | [Towards Fairness in Visual Recognition: Effective Strategies for Bias Mitigation](https://ieeexplore.ieee.org/document/9156668)                                                                                                                            | Zeyu Wang; Klint Qinami; Ioannis Christos Karakozis; Kyle Genova; Prem Nair; Kenji Hata; Olga Russakovsky            | IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)                                                     | 2020       | Gender                     |                                                                                 | Image        | [CIFAR-10 Skewed (CIFAR-10S)](https://www.cs.toronto.edu/~kriz/cifar.html)                                                                                                                                   | 50k                                                                                                                                                                                                                            | 92                                                                                                                                 |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |           |   |                                                                |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
| 15 | [Mitigating Bias in Face Recognition Using Skewness-Aware Reinforcement Learning](https://ieeexplore.ieee.org/document/9156925)                                                                                                                             | Mei Wang; Weihong Deng                                                                                               | IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)                                                     | 2020       | Gender                     |                                                                                 | Image        | [BUPT-Globalface and BUPT-Balancedface datasets to train and RFW to measure performance](http://www.whdeng.cn/RFW/Trainingdataste.html)                                                                      | 1.3M images from 28K celebrities and is approximately race-balanced with 7K identities per race                                                                                                                                | 95.79                                                                                                                              |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |           |   |                                                                |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
| 16 | [Domain Balancing: Face Recognition on Long-Tailed Domains](https://ieeexplore.ieee.org/document/9157174)                                                                                                                                                   | Dong Cao; Xiangyu Zhu; Xingyu Huang; Jianzhu Guo; Zhen Lei                                                           | IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)                                                     | 2020       | Race                       |                                                                                 | Image        | CASIA-Webface and MS-Celeb-1M - MS1Mv2 for train, RFW(http://www.whdeng.cn/RFW/Trainingdataste.html) and AFW for tests                                                                                       | 6.3M training, ref-table 1                                                                                                                                                                                                     |                                                                                                                                    |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |           |   |                                                                |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
| 17 | [Generalizing MLPs With Dropouts,Batch Normalization,and Skip Connections](https://paperswithcode.com/paper/generalizing-mlps-with-dropouts-batch)                                                                                                          | Taewoon Kim                                                                                                          | NeurIPS                                                                                                                   | 2021       | Gender                     | https://github.com/tae898/age-gender                                            | Image        | [Adience]( https://paperswithcode.com/dataset/adience) + IMDB-WIKI                                                                                                                                           | 415306 images                                                                                                                                                                                                                  | 90.66                                                                                                                              |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |           |   |                                                                |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
| 18 | [Age and Gender Classification using Convolutional Neural Networks](https://paperswithcode.com/paper/age-and-gender-classification-using)                                                                                                                   |  Gil Levi, Tal Hassner                                                                                               | IEEE Conference on Computer Vision and Pattern Recognition Workshops                                                      | 2015       | Gender                     | https://github.com/GilLevi/AgeGenderDeepLearning/tree/master                    | Image        | [Adience]( https://paperswithcode.com/dataset/adience)                                                                                                                                                       | 26K images                                                                                                                                                                                                                     | 86.8                                                                                                                               |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |           |   |                                                                |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
| 19 | [Recognizing Human Races through Machine Learning—A Multi-Network, Multi-Features Study](https://www.mdpi.com/2227-7390/9/2/195)                                                                                                                            | Adrian Sergiu Darabant, Diana Borza and Radu Danescu                                                                 | Journal of Mathematics                                                                                                    | 2021       | Race                       |                                                                                 | Image        | [FaceARd dataset]https://www.cs.ubbcluj.ro/~dadi/FaceARG-database.html                                                                                                                                       | 175K train images                                                                                                                                                                                                              |                                                                                                                                    |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |           |   |                                                                |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
| 20 | [FaceNet: A Unified Embedding for Face Recognition and Clustering](https://arxiv.org/abs/1503.03832)                                                                                                                                                        | Florian Schroff, Dmitry Kalenichenko, James Philbin                                                                  |  IEEE Computer Society Conference on Computer Vision and Pattern Recognition 2015                                         | 2015, 2021 | Race                       | https://github.com/wondonghyeon/face-classification                             | image,Video  | http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html                                                                                                                                                             | 1M for testing                                                                                                                                                                                                                 | 99.63                                                                                                                              |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |           |   |                                                                |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
| 21 | [Automatic Ethnicity Classification from Middle Part of the Face Using Convolutional Neural Networks](https://www.mdpi.com/2227-9709/9/1/18)                                                                                                                | David Belcar, Petra Grd and Igor Tomičić                                                                             | Journal of Informatics                                                                                                    | 2022       | Race                       |                                                                                 | Image        | UTK Face, FairFace                                                                                                                                                                                           | 73630 images                                                                                                                                                                                                                   | 80.34                                                                                                                              |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |           |   |                                                                |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
| 22 | [Race Classification from Face using Deep Convolutional Neural Networks](https://ieeexplore.ieee.org/abstract/document/8610704)                                                                                                                             | Xulei Wu; Peijiang Yuan; Tianmiao Wang; Doudou Gao; Ying Cai                                                         | International Conference on Advanced Robotics and Mechatronics                                                            | 2018       | Race                       |                                                                                 | Image        | FERET, [LFW database](http://vis-www.cs.umass.edu/lfw/)                                                                                                                                                      | 130908 training images, 6k Validation                                                                                                                                                                                          | 99.54                                                                                                                              |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |           |   |                                                                |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
| 23 | [Convolutional Neural Network for Ethnicity Classification using Ocular Region in Mobile Environment](https://ieeexplore.ieee.org/abstract/document/8674194)                                                                                                | Ahmad Saeed Mohammad; Jabir Alshehabi Al-Ani                                                                         | Computer Science and Electronic Engineering                                                                               | 2018       | Race                       |                                                                                 | Image        | FERET                                                                                                                                                                                                        | 2730 images                                                                                                                                                                                                                    | 97.83                                                                                                                              |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |           |   |                                                                |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
|    | [What We Teach about Race and Gender: Representation in Images and Text of Children's Books](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4462613)                                                                                                   | Adukia, Anjali and Eble, Alex and Harrison, Emileigh and Runesha, Hakizumwami Birali and Szasz, Teodora              | Journal of Economics                                                                                                      | 2023       | Race, Gender               | https://github.com/miielab/replication_qje_whatweteach                          | Image        |                                                                                                                                                                                                              | images, text in 1130 books                                                                                                                                                                                                     |                                                                                                                                    |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |           |   |                                                                |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
|    | [An AI Method to Score Celebrity Visual Potential from Human Faces](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4462613)                                                                                                                            | Feng, Xiaohang (Flora) and Zhang, Shunyuan and Liu, Xiao and Srinivasan, Kannan and Lamberton, Cait Poynor           |                                                                                                                           | 2021       | Race,Gender                |                                                                                 | Image        | CelebA, IMDB-WIKI, LFW, Google Facial Expression Comparison, CFD, GENKI-4K, MTFL, Selfie Dataset, FFHQ                                                                                                       | 722,418 celebrity images and 158,611 non-celebrity images, 12,000 images for training and 10,000 for testing                                                                                                                   | 95.92                                                                                                                              |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |           |   |                                                                |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
|    | [Bias in the Metaverse: Gender and Racial Price Disparities in the NFT Marketplace]                                                                                                                                                                         |                                                                                                                      |                                                                                                                           |            | Race,Gender                |                                                                                 | NFT          | Opensea.com, CryptoPunks (from January 2021 to June 2022), World of Women (December 2021 to June 2022), and Azuki (December 2021 to June 2022), ETH/USD exchange rate from Yahoo Finance, Twitter Buyer data | 17530 NFT assets and 46821 transactions, analysis performed on 14151 transactions                                                                                                                                              |                                                                                                                                    |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |           |   |                                                                |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
|    | [Face Gender Recognition Based on 2D Principal Component Analysis and Support Vector Machine](https://ieeexplore.ieee.org/abstract/document/5635939)                                                                                                        | L. Bui, D. Tran, Xu Huang, G. Chetty                                                                                 | 2010 Fourth International Conference on Network and System Security (IEEE)                                                | 2010       | Gender                     |                                                                                 | Image        | FERET database was collected at George Mason University between August 1993 and July 1996.                                                                                                                   | 14,126 images stored in 1564 sets for 1199 individuals and 365 duplicate sets.                                                                                                                                                 | https://ieeexplore.ieee.org/abstract/document/5635939                                                                              | This method employs 2D Principal Component Analysis, one of the prominent methods for extracting feature vectors, and Support Vector Machine, the most powerful discriminative method for classification. Experiments for the proposed approach have been conducted on FERET data set and the results show that the proposed method could improve the classification rates.                                                                                                                                                                                                          | Not quite |   | Econometrica                                                   |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
|    | [Cascaded classification of gender and facial expression using active appearance models](https://ieeexplore.ieee.org/document/1613052)                                                                                                                      | Yunus Saatci, C. Town                                                                                                | 7th International Conference on Automatic Face and Gesture Recognition (FGR06)                                            | 2006       | Gender                     |                                                                                 | Image        | Purdue AR dataset, the IMM dataset by the Denmark Technical University and the FEEDTUM dataset of the FG-NET consortium 1                                                                                    | 1,135 samples                                                                                                                                                                                                                  | https://ieeexplore.ieee.org/document/1613052                                                                                       | The means of active appearance models (AAM) extracts features that are used to construct SVM classifiers which are further arranced into a cascade structure to optimise recognition performance. Cascades are an efficient and effective way of performing multi-class recognition of facial expressions.                                                                                                                                                                                                                                                                           | Not quite |   | Review of Economic Studies                                     |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
|    | [Face gender recognition using improved appearance-based Average Face Difference and support vector machine](https://ieeexplore.ieee.org/document/5551728)                                                                                                  | Jing-Ming Guo, Chengyan Lin, H. Nguyen                                                                               | 2010 International Conference on System Science and Engineering                                                           | 2010       | Gender                     |                                                                                 | Image        | The color Feret face database                                                                                                                                                                                | 14,126 images from 1,199 individuals                                                                                                                                                                                           | https://ieeexplore.ieee.org/document/5551728                                                                                       | The improved Appearance-based Average Face Difference (AAFD) scheme exploits the proposed face gender mask to determine the key areas in a face to classify its gender. It is effective in improving the training time, recognition accuracy rate, and efficiency of overall system process.                                                                                                                                                                                                                                                                                         | Not quite |   | Quarterly journal of Economics                                 |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
|    | [FaceGenderID: Exploiting Gender Information in DCNNs Face Recognition Systems](https://ieeexplore.ieee.org/document/9025435)                                                                                                                               | Ruben Vera-Rodriguez; Marta Blazquez; Aythami Morales; Ester Gonzalez-Sosa                                           | 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition                                                       | 2019       | Gender                     | https://github.com/BiDAlab/FaceGenderID                                         | Image        | The VGGFace2 database; Images were downloaded from Google Image Search and have large variations in pose, age, illumination and ethnicity. (<br>Available at: https://github.com/BiDAlab/DiveFace)           | 3.31 million images of 9,131 subjects, with an average of 362.6 images per subject (varying between 80 and 843 images for each identity)                                                                                       | https://ieeexplore.ieee.org/document/9025435                                                                                       | This paper addresses the effect of gender as a covariate in face verification systems to solve the problem of features obtained by previous biased models using very large datasets. It uses triplet loss learning algorithm to train both gender spcific DCNNs models and a gender balanced CNN model to develop a global face recognition system.                                                                                                                                                                                                                                  | Yes       |   | Journal of Political Economy                                   |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
|    | [Fusion of Domain-Specific and Trainable Features for Gender Recognition From Face Images](https://ieeexplore.ieee.org/document/8331979)                                                                                                                    | G. Azzopardi, Antonio Greco, Alessia Saggese, M. Vento                                                               | IEEE Access                                                                                                               | 2018       | Gender                     |                                                                                 | Image        | GENDER-FERET, LFW, UNISA-Public                                                                                                                                                                              | FERET: 474 training (237 males and 237 females) and 472 test (236 males and 236 females) images; LFW:  more than 13, 000 images of 5, 749 subjects; UNISA-Public: 406 faces of 58 different persons (42m, 16f)                 | https://ieeexplore.ieee.org/document/8331979                                                                                       | This paper proposes a novel appraoch that fuses domain-specific and trainable features to recognize the gender from face images. It uses SURF descriptors extracted from 51 facial landmarks as domain-dependent features and the COSFIRE filters as trainable features. It is robust to well-known face variations.                                                                                                                                                                                                                                                                 | Not quite |   | Journal of Marketing Research                                  |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
|    | [Boosting Sex Identification Performance](https://link.springer.com/article/10.1007/s11263-006-8910-9)                                                                                                                                                      | Shumeet Baluja & Henry A. Rowley                                                                                     | International Journal of Computer Vision                                                                                  | 2007       | Gender                     |                                                                                 | Image        | Color FERET database                                                                                                                                                                                         | 994 people (591 male, 403 female); use only frontal images labeled “fa” and<br>“fb” in the database                                                                                                                            | https://link.springer.com/article/10.1007/s11263-006-8910-9                                                                        | This paper presents a method based on AdaBoost to identify the sex of a person from a low resolution grayscale picture of their face. This method achieves 93% accuracy that surpasses the accuracies of the SVM-based classifiers and yields performance 50 times faster.                                                                                                                                                                                                                                                                                                           | Yes       |   |                                                                |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
|    | [Real-Time Embedded Age and Gender Classification in Unconstrained Video](<br><br>https://www.cv-foundation.org/openaccess/content_cvpr_workshops_2015/W12/html/Azarmehr_Real-Time_Embedded_Age_2015_CVPR_paper.html<br><br>)                               | Ramin Azarmehr, Robert Laganiere, Won-Sook Lee, Christina Xu, Daniel Laroche                                         | IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshops                                               | 2015       | Gender                     |                                                                                 | Video        | Training: FERET(FA), MORPH, Gallagher; Evaluation: FERET(fb), Adience, BioID, PAL                                                                                                                            | 8140 male, 7820 female (training); 5455 male, 6206 female (evaluation)                                                                                                                                                         | https://www.cv-foundation.org/openaccess/content_cvpr_workshops_2015/W12/html/Azarmehr_Real-Time_Embedded_Age_2015_CVPR_paper.html | This paper presents a complete framework for video-based age and gender classification which uses a sgemental dimensionality reduction technique using Enhanced Discriminant Analysis (EDA) to reduce memory requirements up to 99.5%. It also exploits a non-linear SVM along with a discriminative demographics classification strategy to improve accuracy.                                                                                                                                                                                                                       | Yes       |   | Journal of Consumer Research                                   |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
|    | [Gender recognition from face images using trainable shape and color features](https://ieeexplore.ieee.org/document/8545771)                                                                                                                                | G. Azzopardi, P. Foggia, Antonio Greco, Alessia Saggese, M. Vento                                                    | International Conference on Pattern Recognition                                                                           | 2018       | Gender                     |                                                                                 | Image        | GENDER-COLOR-FERET                                                                                                                                                                                           | 836 images (418 male and 418 female)                                                                                                                                                                                           | https://ieeexplore.ieee.org/document/8545771                                                                                       | This paper describes an automatic procedure that combines trainable shape and color features for gender classification. It fuses edge-based and color-blob-based features by means of trainable CORFIRE filters.                                                                                                                                                                                                                                                                                                                                                                     |           |   |                                                                |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
|    | [Fast gender recognition in videos using a novel descriptor based on the gradient magnitudes of facial landmarks](https://ieeexplore.ieee.org/abstract/document/8078525)                                                                                    | G. Azzopardi, A. Greco, A. Saggese and M. Vento                                                                      | 2017 14th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS)                            | 2017       | Gender                     |                                                                                 | Image, Video | GENDER-COLOR-FERET                                                                                                                                                                                           | 836 images (418 male and 418 female)                                                                                                                                                                                           | https://ieeexplore.ieee.org/abstract/document/8078525                                                                              | This paper proposes a novel face descriptor based on the gradient magnitudes of facial landmarks to analyze the computational impact related to the proessing of faces extracted from videos captured in the wild.                                                                                                                                                                                                                                                                                                                                                                   |           |   | Quantitative Marketing and Economics                           |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
|    | [Gender classification from unconstrained video sequences](https://ieeexplore.ieee.org/document/5543829)                                                                                                                                                    | M. Demirkus, M. Toews, James J. Clark, T. Arbel                                                                      | 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition                                          | 2010       | Gender                     |                                                                                 | Video        | FERET                                                                                                                                                                                                        | 890 images (445 male and 445 female)                                                                                                                                                                                           | https://ieeexplore.ieee.org/document/5543829                                                                                       | This paper presents the first investigation into the gender classification of faces from unconstrained video sequences in natural scenes. It uses a novel Bayesian formulation to estimate the posterior probabiltiy of a face trait at a specific time, conditional on features identified in previous frames of a video swquence.                                                                                                                                                                                                                                                  | Yes       |   | The Proceedings of the National Academy of Sciences (PNAS)     |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
|    | [Gender Recognition in Non Controlled Environments](https://ieeexplore.ieee.org/document/1699655)                                                                                                                                                           | A. Lapedriza; M.J. Marin-Jimenez; J. Vitria                                                                          | 18th International Conference on Pattern Recognition                                                                      | 2006       | Gender                     |                                                                                 | Image        | FRGC Database (http://www.bee-biometrics.org/)                                                                                                                                                               | two sets of images: 3440 and 1886 samples under controlled conditions and acquired in cluttered scenes respectively                                                                                                            | https://ieeexplore.ieee.org/document/1699655                                                                                       | This paper presents a system to extract robust face features to encode information from any zone of the face and that can be used for different face classification problems., inlcuding gender classification.                                                                                                                                                                                                                                                                                                                                                                      | Yes       |   | Science                                                        |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
|    | [Combining motion and appearance for gender classification from video sequences](https://ieeexplore.ieee.org/document/4760995)                                                                                                                              | A. Hadid, M. Pietikäinen                                                                                             | International Conference on Pattern Recognition                                                                           | 2008       | Gender                     |                                                                                 | Video        | Video face databases including CRIM, VidTIMIT, Cohn-Kanade                                                                                                                                                   | CRIM: 591 face sequences showing 20 people (10 male, 10 female); VidTIMIT: audio recordings and video sequences of 43 subjects (24male, 19 female); Cohn-Kanade: 100 subjects expressing different emotions                    | https://ieeexplore.ieee.org/document/4760995                                                                                       | This paper finds that combining motion and appearance is useful for gender analysis of familiar faces, yielding in classification accuracy of 100%. For unfamiliar faces, motion does not provide discriminative information as the best performance is obtained using an appearance approach with LBP features and SVMs.                                                                                                                                                                                                                                                            |           |   | Nature Human Behavior                                          |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
|    | [Gender classification in live videos](https://ieeexplore.ieee.org/document/8296552)                                                                                                                                                                        | Jiale Chen; Sen Liu; Zhibo Chen                                                                                      | 2017 IEEE International Conference on Image Processing (ICIP)                                                             | 2017       | Gender                     |                                                                                 | Image, Video | Built a real-world live videos dataset called Gender Classification for Live Videos (GCL V) for training; Labeled Faces in the Wild (LFW) dataset and IMDB, IMDB-WIKI datasets for testing                   | GCL V: 5969 live videos, including 3, 025 male videos and 2, 944 female videos; LFW: 13, 233 face images (10, 256 male and 2, 977 female) from 5, 749 celebrities; IMDB-WIKI: 524, 230 face images                             | https://ieeexplore.ieee.org/document/8296552                                                                                       | This paper proposes the Multi-Branch Voting CNN (MBV-CNN) framework which first detects and exracts human face images in live videos, then apply adaptive brightness enhancement and feed them into three CNN branches to settle the illumination problem , and finally apply a majority voting shceme to reduce influnces from motion blur and object occlusion.                                                                                                                                                                                                                    |           |   | International Conference on Machine Learning (ICML)            |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
|    | [Race recognition from face images using Weber local descriptor](https://ieeexplore.ieee.org/document/6208166)                                                                                                                                              | G. Muhammad, M. Hussain, F. Alenezy, G. Bebis, Anwar M. Mirza, Hatim Aboalsamh                                       | 2012 19th International Conference on Systems, Signals and Image Processing (IWSSIP)                                      | 2012       | Race                       |                                                                                 | Image        | Feret database                                                                                                                                                                                               | 1180 images from the major five race group                                                                                                                                                                                     | https://ieeexplore.ieee.org/document/6208166                                                                                       | This paper proposes a race recognition system from face images based on Weber local descriptors (WLD).                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |           |   | WWW                                                            |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
|    | [Ethnicity estimation with facial images](https://ieeexplore.ieee.org/abstract/document/1301530)                                                                                                                                                            | S. Hosoi; E. Takikawa; M. Kawade                                                                                     | Sixth IEEE International Conference on Automatic Face and Gesture Recognition                                             | 2004       | Race                       |                                                                                 | Image        | Collected 1991 images as well as images from the HOIP database                                                                                                                                               | 1991 images                                                                                                                                                                                                                    | https://ieeexplore.ieee.org/abstract/document/1301530                                                                              | This paper addresses a novel approach for ethnicity classification with facial images, which uses Gabor wavelets transformation and retina sampling to extract key facial features and SVMs for ethnicity classification.                                                                                                                                                                                                                                                                                                                                                            |           |   | NeurIPS                                                        |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
|    | [Towards race-related face identification: research on skin color transfer](https://ieeexplore.ieee.org/document/1301557)                                                                                                                                   | Lijun Yin; Jingrong Jia; J. Morrissey                                                                                | Sixth IEEE International Conference on Automatic Face and Gesture Recognition                                             | 2004       | Race                       |                                                                                 | Image        | collected 68 images                                                                                                                                                                                          | 68 images                                                                                                                                                                                                                      | https://ieeexplore.ieee.org/document/1301557                                                                                       | This paper develops a novel skin-color transfer algorithm to explore the potential information from racial groups to improve facial identification. It finds that skin color is amongst one of the factors for race identification, but not the dominant one.                                                                                                                                                                                                                                                                                                                        |           |   | AAAI                                                           |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
|    | [Model-Agnostic Gender Debiased Image Captioning](https://openaccess.thecvf.com/content/CVPR2023/html/Hirota_Model-Agnostic_Gender_Debiased_Image_Captioning_CVPR_2023_paper.html)                                                                          | Yusuke Hirota, Yuta Nakashima, Noa Garcia                                                                            | CVPR 2023                                                                                                                 | 2023       | Gender                     |                                                                                 | Image        | MSCOCO dataset                                                                                                                                                                                               | 82,783 images                                                                                                                                                                                                                  | https://openaccess.thecvf.com/content/CVPR2023/html/Hirota_Model-Agnostic_Gender_Debiased_Image_Captioning_CVPR_2023_paper.html    | This paper mitigates two types of gender biases affecting image captioning models by proposing a framedwork LIBRA that learns from sythetically biased samples in order to correct gender misclassification.                                                                                                                                                                                                                                                                                                                                                                         |           | 1 | IEEE/CVF Conference on Computer Vision and Pattern Recognition | 422 | 681 |   |   |   |   |   |   |   |   |   |   |   |   |   |
|    | [Racial faces in the wild: Reducing racial bias by information maximization adaptation network]                                                                                                                                                             |                                                                                                                      |                                                                                                                           |            |                            |                                                                                 |              |                                                                                                                                                                                                              |                                                                                                                                                                                                                                |                                                                                                                                    |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |           | 2 | European Conference on Computer Vision                         | 238 | 390 |   |   |   |   |   |   |   |   |   |   |   |   |   |
|    | [Cross-database evaluation on normalized raw pixels for gender recognition under unconstrained settings](https://ieeexplore.ieee.org/document/4454030)                                                                                                      | Taner Danisman; Ioan Marius Bilasco; Chabane Djeraba                                                                 | 2014 22nd International Conference on Pattern Recognition                                                                 | 2014       | Gender                     |                                                                                 | Image        | LFW, Genki-4K and Groups databases                                                                                                                                                                           | Groups: 5080 images; LFW: 13233 images; Genki-4K: 4000 images                                                                                                                                                                  | https://ieeexplore.ieee.org/document/4454030                                                                                       | This paper presents corss-database evaluations of automatic appearance-based gender recognition method using normalized raw pixels and SVM classififer under unconstratined settings. Highest crossdatabase accuracies: over 90%.                                                                                                                                                                                                                                                                                                                                                    |           | 3 | IEEE/CVF International Conference on Computer Vision           | 228 | 366 |   |   |   |   |   |   |   |   |   |   |   |   |   |
|    | [Single and cross-database benchmarks for gender classification under unconstrained settings](https://ieeexplore.ieee.org/document/6130514)                                                                                                                 | Pablo Dago-Casas; Daniel González-Jiménez; Long Long Yu; José Luis Alba-Castro                                       | 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops)                                          | 2011       | Gender                     |                                                                                 | Image        | LFW; Gallafgher's database                                                                                                                                                                                   | Gallagher's databse: 28,231 labeled face images; LFW: 13,233 labeled images from 5749 individuals                                                                                                                              | https://ieeexplore.ieee.org/document/6130514                                                                                       |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |           |   |                                                                |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
|    | [Revisiting Linear Discriminant Techniques in Gender Recognition](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5661777)                                                                                                                             | J. Bekios-Calfa, J. Buenaposada, and L. Baumela.                                                                     | IEEE Transactions on Pattern Analysis and Machine Intelligence                                                            | 2011       | Gender                     |                                                                                 | Image        | Nonpublic databse from UCN in Chile (UCN database), the Color FERET database, the Productive Aging Lab database from University of Texas at Dallas                                                           | UCN: 5628 male images of 5646 male and 5041 female images of 5054 female; Color FERET: 402 female images; PAL Databse: 219 male and 367 female subjects                                                                        | https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5661777                                                                       | This paper reviews the state-of-art in gender recognition. For single databse experiements, it confirms similar classififcation accuracies for SVMs and pixel-wise boosting algorithms (SVM slightly better for larger databse). Linear techniques also achieve similar accuracies including ICA+LDA, PCA-M+LDA, and PCA+LDA. Single database experiments are positively biased. If using different databases, SVM+RBF achieves 80% for sample size >10,000; all tested approaches have similar accuracies for sample size - [500, 1000]; PCA+LDA is the best for sample size <300.  |           |   |                                                                |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
|    | [Real Time Emotion Recognition and Gender Classification](https://ieeexplore.ieee.org/document/9299633)                                                                                                                                                     | Uttara Gogate; Alap Parate; Shubham Sah; Sagar Narayanan                                                             | 2020 International Conference on Smart Innovations in Design, Environment, Management, Planning and Computing (ICSIDEMPC) | 2020       | Gender                     | https://paperswithcode.com/paper/real-time-convolutional-neural-networks-for    | Image, Video | IMDb database                                                                                                                                                                                                | 460,723 RGB images                                                                                                                                                                                                             | https://ieeexplore.ieee.org/document/9299633                                                                                       | This paper proposes prototype aims to classify the gender and the emotions of a person in real time (or using the image). It uses CNN for gender classification and achieves 95% accuracy.                                                                                                                                                                                                                                                                                                                                                                                           |           |   |                                                                |     |     |   |   |   |   |   |   |   |   |   |   |   |   |   |
